{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a71f79f",
   "metadata": {},
   "source": [
    "## 深度学习计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9014e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cac0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4991, -0.2851, -0.0465,  0.0492, -0.3156,  0.2185, -0.2036, -0.0525,\n",
      "         -0.4470, -0.1752],\n",
      "        [ 0.4347, -0.2926,  0.5307,  0.4380, -0.4316,  0.2426, -0.6666,  0.1185,\n",
      "         -0.0972,  0.0773]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(20, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))\n",
    "X = torch.randn(2, 20)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87133eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61d96e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2698,  0.1221,  0.0640, -0.0645,  0.0584,  0.1774, -0.2562,  0.0208,\n",
      "         -0.0652, -0.2183],\n",
      "        [ 0.0331, -0.0116, -0.0227, -0.1497,  0.1637,  0.6946, -0.1518,  0.6945,\n",
      "         -0.0137, -0.8431]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = MLP()\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5a7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for module in self._modules.values():\n",
    "            X = module(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdf7d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0503,  0.2224, -0.2909, -0.3664, -0.3681,  0.0506, -0.0514, -0.1537,\n",
      "          0.1903,  0.4282],\n",
      "        [ 0.2772, -0.0137, -0.3113, -0.0985,  0.3356,  0.4591,  0.2226,  0.0769,\n",
      "          0.3688,  0.8713]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net  = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c52a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        \n",
    "        return self.linear(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "626daa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0773,  0.2476,  0.1560, -0.0445,  0.1721,  0.0442,  0.1749, -0.0615,\n",
      "         -0.2389,  0.1722, -0.1484, -0.2001,  0.0007, -0.0301,  0.1026, -0.1920,\n",
      "         -0.2003, -0.0263,  0.0253, -0.0542],\n",
      "        [ 0.0459,  0.2142,  0.1855, -0.0157,  0.1729,  0.0882,  0.1543, -0.0593,\n",
      "         -0.2242,  0.1402, -0.1784, -0.1755,  0.0451, -0.0114,  0.0934, -0.2018,\n",
      "         -0.1820, -0.0539,  0.0309, -0.0463]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f501851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3750e-01,  1.2581e-02,  3.9144e-02, -4.5786e-02,  1.4665e-01,\n",
       "          9.1764e-02, -1.2198e-01, -7.4244e-02,  8.0128e-03,  8.8010e-05,\n",
       "         -2.3515e-02,  2.0612e-02,  1.0110e-01, -2.1562e-01,  1.3709e-01,\n",
       "          1.8578e-01, -1.3833e-01, -9.5749e-02, -1.3792e-01,  1.7625e-01],\n",
       "        [ 1.3785e-01,  1.3485e-02,  3.9002e-02, -4.5999e-02,  1.4709e-01,\n",
       "          9.1931e-02, -1.2206e-01, -7.4625e-02,  7.3047e-03, -2.3676e-04,\n",
       "         -2.3358e-02,  2.0685e-02,  1.0151e-01, -2.1587e-01,  1.3729e-01,\n",
       "          1.8540e-01, -1.3845e-01, -9.6155e-02, -1.3792e-01,  1.7633e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa09bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1399],\n",
      "        [-0.1189]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "X = torch.randn(2, 4)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb086f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.2076, -0.2971, -0.1239, -0.3278,  0.1315,  0.0702,  0.1360,  0.3372]])), ('bias', tensor([-0.1265]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1913e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.1265], requires_grad=True)\n",
      "tensor([-0.1265])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)\n",
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28a0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34e2debc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1265])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b949dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3294],\n",
      "        [-0.3294]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "print(rgnet(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "627ef55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f515862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4189, -0.3938, -0.3104,  0.0105, -0.1262,  0.2937,  0.4695,  0.2360])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "726fca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0028, -0.0039, -0.0047,  0.0181]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "print(net[0].weight.data[0], net[0].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d880b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0023,  0.0072,  0.0058, -0.0059]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(initialize_weights)\n",
    "print(net[0].weight.data[0], net[0].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89d4dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2646, -0.3179, -0.0592,  0.5297])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight,42)\n",
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86219b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init ('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "Init ('weight', torch.Size([1, 8])) ('bias', torch.Size([1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3597, -0.0000,  5.7331,  0.0000],\n",
       "        [ 0.0000, -5.7184,  0.0000, -8.0952]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\",*[(name,param.shape) for name,param in m.named_parameters()])\n",
    "        nn.init.uniform_(m.weight,-10,10)\n",
    "        m.weight.data *=m.weight.data.abs()>=5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6832a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6403,  8.0000, 13.7331,  8.0000],\n",
      "        [ 8.0000,  2.2816,  8.0000, -0.0952],\n",
      "        [-1.1097,  8.0000, 14.1464,  8.0000],\n",
      "        [ 8.0000,  2.1192, 15.5830,  8.0000],\n",
      "        [ 8.0000,  8.0000,  8.0000,  8.0000],\n",
      "        [-0.8041,  8.0000,  8.0000, 13.1649],\n",
      "        [ 8.0000, 14.9392,  2.9329,  8.0000],\n",
      "        [17.4399,  8.0000, 17.9835,  8.0000]])\n",
      "tensor([[ 3.6403,  9.0000, 14.7331,  9.0000],\n",
      "        [ 9.0000,  3.2816,  9.0000,  0.9048],\n",
      "        [-0.1097,  9.0000, 15.1464,  9.0000],\n",
      "        [ 9.0000,  3.1192, 16.5830,  9.0000],\n",
      "        [ 9.0000,  9.0000,  9.0000,  9.0000],\n",
      "        [ 0.1959,  9.0000,  9.0000, 14.1649],\n",
      "        [ 9.0000, 15.9392,  3.9329,  9.0000],\n",
      "        [18.4399,  9.0000, 18.9835,  9.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net[0].weight.data)\n",
    "net[0].weight.data[:] +=1\n",
    "print(net[0].weight.data)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9ea57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "shared = nn.Linear(8,8)\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.ReLU(),shared,nn.ReLU(),nn.Linear(8,1))\n",
    "net(X)\n",
    "print(net[2].weight.data[0]==net[4].weight.data[0])\n",
    "net[2].weight.data[0,0] = 100\n",
    "print(net[2].weight.data[0]==net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cee6f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenteredLayyer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,X):\n",
    "        return X-X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7ddd1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayyer()\n",
    "layer(torch.FloatTensor([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bce95d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5193e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(8,128),CenteredLayyer()\n",
    ")\n",
    "Y = net(torch.rand(4,8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4a7dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,in_units,units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units,units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self,X):\n",
    "        linear = torch.matmul(X,self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bd220d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9146,  1.3321, -1.7771],\n",
       "        [ 1.0491,  0.0602,  1.2255],\n",
       "        [-0.5873,  0.8492, -1.2646],\n",
       "        [-0.2423, -0.6302, -1.2189],\n",
       "        [-1.2080, -0.8825, -2.7891]], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5,3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4676fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0996],\n",
       "        [0.0000, 0.0108, 0.0000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc0a3dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    MyLinear(64,8),MyLinear(8,1)\n",
    ")\n",
    "net(torch.rand(2,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cb7bae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x,'x-file')\n",
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc9fdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size = (2,20))\n",
    "Y = net(X)\n",
    "torch.save(net.state_dict(),'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1449bb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cafe63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "839e50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() >= i:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2795caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), device(type='cpu'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_gpu(),try_gpu(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8cb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
